# remote-model-access
Allows you to chat with a llm from a separate device on the same wifi on an iphone or with tailscale, from anywhere.

Ill put more info and files here soon

# how to use
ğŸ”° Download the zip file in RELEASES.

ğŸ”° Install the resulted .ipa file with whatever signer you use (feather, esign, gbox, etc.

ğŸ”° Inside the app, put it in at least the Server Endpoint and API Key.

ğŸ”° Now you should be good, as long as you're connected through wireguard (I used tailscale) or on the same wifi.

## I used LM Studio to host a llm, but you can use ollama or others as long as they give you a working server endpoint and api key.

# features (this is kind of simple but still)
â¤ï¸â€ğŸ”¥ Connect to an llm running locally on your computer from your âœ¨iphoneâœ¨

â¤ï¸â€ğŸ”¥ Make multiple chats
 
 # coming soon (eventually) (not in order)
ğŸ‘€ Video turorial

ğŸ‘€ Apple watch app

ğŸ‘€ Renaming chats

ğŸ‘€ Send images

ğŸ‘€ Loading indicator

ğŸ‘€ Multiple models

ğŸ‘€ Apple TV app (Maybe)

ğŸ‘€ Saving llm presets (Maybe)
