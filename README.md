# remote-model-access
Allows you to chat with a llm from a separate device on the same wifi on an iphone.
This was made in Xcode, and I dont have an apple developer account so I cant make this an .ipa, unless I find some other way.
Ill put more info and files here soon
Originally this was to be used with tailscale but im not sure if tailscale will help.
# how to use
🔰 Download the zip file in RELEASES.

🔰 After unzipping, open it with Xcode.

🔰 Pair your iPhone with Xcode.

🔰 Select your iPhone as a run destination and run it.

🔰 The app should then download to your iPhone.

🔰 In the app, put it in at least the Server Endpoint and API Key.

🔰 Now you should be good, as long as you're connected through wireguard (I used tailscale) or on the same wifi.

## I used LM Studio to host a llm, but you can use ollama or others as long as they give you a working server endpoint and api key.

# features (this is kind of simple but still)
❤️‍🔥 Connect to an llm running locally on your computer from your ✨iphone✨

❤️‍🔥 Make multiple chats
 
 # coming soon (eventually) (not in order)
👀 Video turorial

👀 Apple watch app

👀 Renaming chats

👀 Send images

👀 Loading indicator

👀 Multiple models

👀 Apple TV app (Maybe)

👀 Saving llm presets (Maybe)
